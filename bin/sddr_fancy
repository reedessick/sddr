#!/usr/bin/env python

__usage__ = "sddr_fancy [--options] samples.hdf5 [samples.hdf5 samples.hdf5 ...]"
__doc__ = "an executable that computes things"
__author__ = "reed.essick@ligo.org"

#-------------------------------------------------

import os
import numpy as np

import matplotlib
matplotlib.use("Agg")
from matplotlib import pyplot as plt
plt.rcParams['text.usetex'] = True

from optparse import OptionParser

### non-standard libraries
from sddr import utils

#-------------------------------------------------

def report(points, logpost, logprior, confidence):
    print '''\
logpost = %.6f
logprior = %.6f
logpost - logprior = %.6f'''%(logpost[0], logprior, logpost[0]-logprior)
    s = np.cumsum(np.exp(logpost)*np.gradient(points))
    for conf in confidence:
        print '    A <= %.6e @ %.1f condifence'%(points[s<=conf][-1], 100*conf)

def b2logpost(points, samples, weights, b, prior_min, prior_max):
    logpost = [utils.kde(logpoint, samples, weights, b, prior_min=prior_min, prior_max=prior_max) for logpoint in np.log10(points)]
    m = np.max(logpost)
    logpost = (logpost-m) - np.log(np.trapz(np.exp(logpost-m), points)) ### normalized
    return logpost

def fixed_b(points, samples, weights, b, prior_min, prior_max, confidence=[], verbose=True, ax=None):
    logpost = b2logpost(points, samples, weights, b, prior_min, prior_max)
    logprior = -np.log(np.exp(prior_max)-np.exp(prior_min))
    if verbose:
        report(points, logpost, logprior, confidence)
    if ax is not None:
        ax.plot(points, np.exp(logpost), color='g', label='fixed b')
    return logpost[0]-logprior

def max_b(points, samples, weights, (min_b, max_b), prior_min, prior_max, confidence=[], rtol=1e-4, verbose=True, Verbose=False, ax=None):
    b = utils.optimize_bandwidth(samples, weights, min_b, max_b, rtol=rtol, verbose=verbose)
    if verbose:
        print('    b=%.6e'%b)
    logpost = b2logpost(points, samples, weights, b, prior_min, prior_max)
    logprior = -np.log(np.exp(prior_max)-np.exp(prior_min))
    if verbose:
        report(points, logpost, logprior, confidence)
    if ax is not None:
        ax.plot(points, np.exp(logpost), color='r', label='max b')
    return logpost[0]-logprior

def marg_b(points, samples, weights, (min_b, max_b), prior_min, prior_max, confidence=[], rtol=1e-4, dlogl=8, num_points=100, prior='lin', verbose=True, Verbose=False, ax=None):
    bs, ws = utils.marginalize_bandwidth(samples, weights, min_b, max_b, rtol=rtol, dlogl=dlogl, num_points=num_points, prior=prior, verbose=Verbose)
    logpost = np.zeros_like(points)
    for b, w in zip(bs, ws):
        logpost += w*np.exp(b2logpost(points, samples, weights, b, prior_min, prior_max))
    logpost = np.log(logpost)
    logprior = -np.log(np.exp(prior_max)-np.exp(prior_min))
    if verbose:
        report(points, logpost, logprior, confidence)
    if ax is not None:
        ax.plot(points, np.exp(logpost), color='c', label='marg b')
    return logpost[0]-logprior

#-------------------------------------------------

parser = OptionParser(usage=__usage__, description=__doc__)

parser.add_option('-v', '--verbose', default=False, action='store_true')
parser.add_option('-V', '--Verbose', default=False, action='store_true')
parser.add_option('', '--run-subsamp', default=False, action='store_true')

parser.add_option('', '--initial-burnin', default=utils.DEFAULT_INITIAL_BURNIN, type='int',
    help='force the code to skip the first --initial-burnin samples, and then proceed with --deltaLogP logic. \
DEFAULT=%d'%utils.DEFAULT_INITIAL_BURNIN)
parser.add_option('', '--deltaLogP', default=utils.DEFAULT_DELTALOGP, type='float',
    help='used when stripping burn-in from hdf5 files')
parser.add_option('', '--downsample', default=utils.DEFAULT_DOWNSAMPLE, type='int',
    help='only retain 1 out of every --downsample samples after stripping burn-in. Used when reading both file types')

parser.add_option('', '--skip', default=[], type='string', action='append',
    help='skip the computation of this particular estimate. Note, we require an exact match of the name, so these options might be pretty long...')

parser.add_option('', '--num-subsets', default=utils.DEFAULT_NUM_SUBSETS, type='int')
parser.add_option('', '--num-points', default=1000, type='int',
    help='number of evaluation points used when estimating KDE')

parser.add_option('', '--prior-min', default=utils.DEFAULT_PRIOR_MIN, type='float')
parser.add_option('', '--prior-max', default=utils.DEFAULT_PRIOR_MAX, type='float')

parser.add_option('', '--kde-b', default=utils.DEFAULT_B, type='float')

parser.add_option('', '--kde-b-range', nargs=2, default=utils.DEFAULT_B_RANGE, type='float')
parser.add_option('', '--kde-rtol', default=utils.DEFAULT_RTOL, type='float')

parser.add_option('', '--kde-dlogl', default=utils.DEFAULT_DLOGL, type='float')
parser.add_option('', '--kde-num-points', default=utils.DEFAULT_NUM_POINTS, type='int')
parser.add_option('', '--kde-b-prior', default=utils.DEFAULT_B_PRIOR, type='string')

parser.add_option('', '--confidence', default=[], type='float', action='append',
    help='the confidence level for upper limit estimates')

parser.add_option('-o', '--output-dir', default='.', type='string')
parser.add_option('-t', '--tag', default='', type='string')

opts, args = parser.parse_args()
assert args, 'please supply at least 1 input argument\n%s'%__usage__

opts.verbose |= opts.Verbose

if not os.path.exists(opts.output_dir):
    os.makedirs(opts.output_dir)

if opts.tag:
    opts.tag = "_"+opts.tag

logprior = -np.log(10**opts.prior_max - 10**opts.prior_min)
opts.confidence = sorted(opts.confidence)

#-------------------------------------------------

### read in samples, hard code stuff because this is a pretty dedicated script
samples = utils.load(args, field='log10NLTides_A0', deltaLogP=opts.deltaLogP, downsample=opts.downsample, initial_burnin=opts.initial_burnin, verbose=opts.verbose)
weights = np.ones_like(samples, dtype='float')
weights /= np.sum(weights)

### check prior bounds
truth = (opts.prior_min <=samples)*(samples<=opts.prior_max)
samples = samples[truth]
weights = weights[truth]

points = np.linspace(10**opts.prior_min, min(2*10**np.max(samples), 10**opts.prior_max), opts.num_points) ### evaluation points

if opts.run_subsamp:
    if opts.verbose:
        print('partitioning samples into %d subsets'%opts.num_subsets)
    subsets = utils.partition(samples, weights, num_subsets=opts.num_subsets)
    sqrtnum_subsets = opts.num_subsets**0.5

#-------------------------------------------------

# set up figure
fig = plt.figure()
ax = fig.gca()

### handle each method explicitly
# kde with fixed bandwidth
if opts.verbose:
    print('working on kde with reflecting boundaries and b=%.3e'%opts.kde_b)
fixed_b(points, samples, weights, opts.kde_b, opts.prior_min, opts.prior_max, confidence=opts.confidence, ax=ax)
if opts.run_subsamp:
    FIG = plt.figure()
    AX = FIG.gca()
    ans = []
    for subsamp, subweight in subsets:
        ans.append(fixed_b(points, subsamp, subweight, opts.kde_b, opts.prior_min, opts.prior_max, confidence=opts.confidence, ax=AX, verbose=opts.Verbose))
    AX.set_xlabel('A0')
    plt.setp(AX.get_yticklabels(), visible=False)
    AX.grid(True, which='both')
    AX.set_xlim(xmin=points[0], xmax=points[-1])
    figname = '%s/sddr_fancy-fixed_b%s.png'%(opts.output_dir, opts.tag)
    if opts.verbose:
        print('saving: '+figname)
    FIG.savefig(figname)
    plt.close(FIG)
    print('''\
mean(logpost - logprior) = %.6f
stdv(logpost - logprior) = %.6f'''%(np.mean(ans), np.std(ans)))

# kde with maximized bandwidth
if opts.verbose:
    print('working on kde with reflecting boundaries and maximized bandwidth')
max_b(points, samples, weights, opts.kde_b_range, opts.prior_min, opts.prior_max, confidence=opts.confidence, rtol=opts.kde_rtol, Verbose=opts.Verbose, ax=ax)
if opts.run_subsamp:
    FIG = plt.figure()
    AX = FIG.gca()
    ans = []
    for subsamp, subweight in subsets:
        ans.append( max_b(points, subsamp, subweight, opts.kde_b_range, opts.prior_min, opts.prior_max, confidence=opts.confidence, rtol=opts.kde_rtol, verbose=opts.Verbose, ax=AX) )
    AX.set_xlabel('A0')
    plt.setp(AX.get_yticklabels(), visible=False)
    AX.grid(True, which='both')
    AX.set_xlim(xmin=points[0], xmax=points[-1])
    figname = '%s/sddr_fancy-max_b%s.png'%(opts.output_dir, opts.tag)
    if opts.verbose:
        print('saving: '+figname)
    FIG.savefig(figname)
    plt.close(FIG)
    print('''\
mean(logpost - logprior) = %.6f
stdv(logpost - logprior) = %.6f'''%(np.mean(ans), np.std(ans)))

# kde with marginalized bandwidth
if opts.verbose:
    print('working on kde with reflecting boundaries and marginalized bandwidth')
marg_b(points, samples, weights, opts.kde_b_range, opts.prior_min, opts.prior_max, confidence=opts.confidence, rtol=opts.kde_rtol, dlogl=opts.kde_dlogl, num_points=opts.kde_num_points, prior=opts.kde_b_prior, Verbose=opts.Verbose, ax=ax)
if opts.run_subsamp:
    FIG = plt.figure()
    AX = FIG.gca()
    ans = []
    for subsamp, subweight in subsets:
        ans.append(marg_b(points, subsamp, subweight, opts.kde_b_range, opts.prior_min, opts.prior_max, confidence=opts.confidence, rtol=opts.kde_rtol, dlogl=opts.kde_dlogl, num_points=opts.kde_num_points, prior=opts.kde_b_prior, verbose=opts.Verbose, ax=AX))
    AX.set_xlabel('A0')
    plt.setp(AX.get_yticklabels(), visible=False)
    AX.grid(True, which='both')
    AX.set_xlim(xmin=points[0], xmax=points[-1])
    figname = '%s/sddr_fancy-marg_b%s.png'%(opts.output_dir, opts.tag)
    if opts.verbose:
        print('saving: '+figname)
    FIG.savefig(figname)
    plt.close(FIG)
    print('''\
mean(logpost - logprior) = %.6f
stdv(logpost - logprior) = %.6f'''%(np.mean(ans), np.std(ans)))

# save the comparison figure
ax.plot(points, np.exp(logprior)*np.ones_like(points), 'k-', label='prior')

ax.set_xlabel('A0')
plt.setp(ax.get_yticklabels(), visible=False)
ax.grid(True, which='both')
ax.legend(loc='best')
ax.set_xlim(xmin=points[0], xmax=points[-1])
figname = '%s/sddr_fancy%s.png'%(opts.output_dir, opts.tag)
if opts.verbose:
    print('saving: '+figname)
fig.savefig(figname)
plt.close(fig)
